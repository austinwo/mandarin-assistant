# Mandarin AI â€” Write English Like Yourself, Get Mandarin Like a Local

Learn how Chinese speakers actually talk â€” not how textbooks translate.

A Retrieval-Augmented Generation (RAG) system that transforms everyday English into **grounded, native-style Mandarin phrasing** with contextual examples. Built to solve a real user problem: conversational Mandarin acquisition that mirrors how people speak in real life.

---

## âœ¨ What it gives you
- **Native-style Mandarin phrasing** (not literal translation)
- **Chinese output in both ZH Simplified + ZH Traditional**
- **Pinyin pronunciation**
- **Thai-based phonetic pronunciation (ZH-TH)**
- **Mandarin + English usage examples with relevant context**

This moves language learning from **vocabulary memorization** to **situational fluency**.

---

## ðŸš€ Why it's different
Most language tools fail at conversation because they sit at the extremes:

- **Pure translation â†’ rigid, literal, unnatural**
- **Pure LLM â†’ hallucinations, tone drift, no grounding**

Mandarin AI uses a **hybrid retrieval + generation approach**:

**Retrieve â†’ Evaluate â†’ Generate**
1. User query â†’ embedded using a multilingual transformer
2. Vector search for the closest conversational phrase
3. If similarity â‰¥ threshold â†’ return grounded examples
4. If similarity < threshold â†’ GPT-4o-mini generates a natural phrasing

Generation becomes **a controlled fallback**, not a default.

The outcome is real-world Mandarin phrasing that matches how native speakers would actually speak in social settings.

---

# ðŸ”¥ Architecture Overview

### UI Layer (Flask + Bootstrap)
- English input
- â€œTranslateâ€
- â€œðŸŽ² Inspire meâ€
- Loading state
- Prior output cleared during inference

### Retrieval Layer (Chroma + MPNet)
- `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- Multilingual semantic embeddings
- k-nearest neighbor cosine similarity
- Operates without LLM cost for high-confidence matches

### LLM Layer (OpenAI)
- Model: **gpt-4o-mini**
- Structured JSON output:
  - Simplified
  - Traditional
  - Pinyin
  - Thai phonetics
  - Mandarin + English usage examples

### Orchestration
- Retrieval anchors the phrasing
- Generation only extends or interpolates
- The system avoids literal translation and uncontrolled creativity

---

# ðŸ§  Model Choice: Why `gpt-4o-mini`
- Strong latency performance for user-facing workflows
- Consistent JSON-style completions
- Excellent multilingual inference
- Cost-effective for iteration

### When to upgrade
| Scenario | Model |
|---|---|
| Conversational usage | **gpt-4o-mini** |
| Cultural nuance / tutoring | **gpt-4o** |
| Curriculum / reasoning tasks | **gpt-4.1** |

---

# ðŸ› ï¸ Setup

Install dependencies:
```bash
poetry install
```

---

# ðŸ”‘ Configure OpenAI API Key

macOS / Linux / WSL:
```bash
export OPENAI_API_KEY="sk-xxxx"
```

Windows PowerShell:
```bash
setx OPENAI_API_KEY "sk-xxxx"
```

Restart your terminal â€” no `.env` required.

---

# â–¶ï¸ Run the app
```bash
poetry run python app.py
```

Visit:
```
http://127.0.0.1:5000
```

---

# ðŸ’¡ Features

### 1. Conversational translation
```
Where are we going later?
```
Output includes:
- EN reference
- TH
- ZH Traditional
- ZH Simplified
- Pinyin
- ZH-TH (Thai phonetics)
- Usage examples in both Mandarin + English

### 2. ðŸŽ² Inspiration mode
Shows real-life Mandarin examples when users donâ€™t know what to ask.

### 3. UX design around LLMs
- Results hidden while generating
- Buttons disabled during inference
- Loading indicator
- Dark UI for long-session readability

User experience respects **latency and cognitive load**.

---

# âš™ï¸ Internal Logic (high-level)
```
User Input â†’ Embedding (MPNet) â†’ Vector Search (Chroma) â†’ Similarity Threshold â†’ 
Retrieval Output OR GPT-4o-mini JSON â†’ Rendered UI
```

Retrieval constrains the model to **grounded examples**.  
Generation only activates when retrieval confidence is insufficient.

---

# ðŸ›¡ï¸ Reliability & Guardrails
If LLM inference fails:
- Retrieval-only output is returned
- UI remains operational
- User still learns something

Graceful degradation > hard failures.

---

# ðŸ“ˆ Future Roadmap

**1. Personalized memory**
- Store user embeddings to build a language profile over time
- Adapt tone and phrasing to each learnerâ€™s style

**2. Speech mode**
- Whisper input â†’ Mandarin TTS output
- Real conversation practice loops

**3. Anki export**
- Characters, Pinyin, ZH-TH, and usage examples
- Lower friction for spaced repetition

**4. Adaptive difficulty**
- Track familiarity and exposure
- Recommend new phrases intelligently
- Avoid random drilling

**5. Session-aware Mandarin**
- Multi-turn context retention
- Travel, social, and practical domains
- Persona-aware phrasing
